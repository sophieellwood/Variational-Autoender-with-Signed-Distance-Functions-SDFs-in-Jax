# Variational-Autoender-with-Signed-Distance-Functions-SDFs-in-Jax
This experiment explores the application of Autoencoders (AEs) and Variational Autoencoders (VAEs) for implicit representations, specifically signed distance functions. 
Here, the dataset is 2D, but the models can be adapted to 3D.
Inputs: The MNISTSDF dataset. The dataset consists of handwritten digits, but as discrete SDFs instead of binary images.


**Part I**

A VAE trained using a convolutional AE and vanilla Decoder. The model uses ELBO loss, consisting of a reconstruction term and KL divergence.
This model _should_ work with a DeepSDF decoder (included in the code). The decoder should take an input coordinate _in addition to_ 
the latent space vector generated by the encoder. 
However, in practice, this gave poor reconstruction, where the predicted values did not span the whole -1 to 1 range. This is likely an issue with the KL
divergence, as the sampled distribution may be too small.
Instead, here are some results on the test set with a vanilla decoder, and so the SDFs are treated similarly to image values. (Increasing training iterations would give more accurate results).
<div align="center">
<img width="1044" height="282" alt="image" src="https://github.com/user-attachments/assets/839d1615-89c4-4e8c-a86e-135ff878f2ea" />
</div>

We can see that sampling the latent space gives 'imaginary' numbers that still resemble actual values. This is due to using a distribution
to represent the latent space, instead of mapping to a single vector.
<div align="center">
<img width="533" height="483" alt="image" src="https://github.com/user-attachments/assets/513b5ede-c818-42dd-bdd5-49b1ae7306a8" />
</div>

Interpolation also works well.
<div align="center">
<img width="1198" height="122" alt="image" src="https://github.com/user-attachments/assets/764e5029-456b-4636-8779-ea7ddac7bd88" />
</div>

**Part II**

A vanilla encoder transforms input SDFs into latent space vectors. DeepSDF, as the decoder, takes in a coordinate in 2d space and the latent, producing a predicted SDF.
MSE loss is used to optimize the Autoencoder.

Reconstruction:
<div align="center">
<img width="878" height="248" alt="image" src="https://github.com/user-attachments/assets/2aff0556-20c3-4188-8a83-9551b819f8a3" />
</div>

Interpolation between two SDFs randomly selected from the test set:
<div align="center">
<img width="2162" height="364" alt="image" src="https://github.com/user-attachments/assets/4e84deb6-0735-4955-8b14-b4503097541a" />
</div>

Sampling the latent space:
<div align="center">
<img width="371" height="282" alt="image" src="https://github.com/user-attachments/assets/c66dc00e-2d2c-45ed-b9d5-ace52ebfb464" />
</div>
Testing out different latent sizes:
<div align="center">
<img width="302" height="290" alt="image" src="https://github.com/user-attachments/assets/a643dfcc-63d4-40fd-87f9-380ee6b8c72d" />
</div>

**This code was created with the help of the following tutorials and repos:**
- [Tutorial 9 (JAX): Deep Autoencoders](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/JAX/tutorial9/AE_CIFAR10.html)
- [MetaSDF](https://github.com/vsitzmann/metasdf/blob/master/MNISTHypernetworksDemo.ipynb)
- [Fashion MNIST](https://github.com/najeebuddinm98/vae_fashionmnist/blob/main/VAE_fashionmnist.ipynb)
- [Debug a variational autoencoder (VAE)](https://docs.jaxstack.ai/en/stable/digits_vae.html)
- [DeepSDF](https://github.com/facebookresearch/DeepSDF)

