{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sophieellwood/Variational-Autoender-with-Signed-Distance-Functions-SDFs-in-Jax/blob/main/VAE_DeepSDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzM8dwps00ZS"
      },
      "source": [
        "# **Variational autoender with Signed Distance Functions (SDFs) in Jax**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oD-78tS00ZX"
      },
      "source": [
        "<center width=\"100%\"><img src=\"https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial9/autoencoder_visualization.svg?raw=1\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"650px\"/></center>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UUSd03e00ZV"
      },
      "outputs": [],
      "source": [
        "## Standard libraries\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "import numpy as np\n",
        "from scipy import spatial\n",
        "from flax import nnx\n",
        "\n",
        "## Imports for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython.display import set_matplotlib_formats\n",
        "set_matplotlib_formats('svg', 'pdf') # For export\n",
        "from matplotlib.colors import to_rgb\n",
        "import matplotlib\n",
        "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
        "import seaborn as sns\n",
        "sns.reset_orig()\n",
        "sns.set()\n",
        "\n",
        "## Progress bar\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "## To run JAX on TPU in Google Colab, uncomment the two lines below\n",
        "# import jax.tools.colab_tpu\n",
        "# jax.tools.colab_tpu.setup_tpu()\n",
        "\n",
        "## JAX\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "# Seeding for random operations\n",
        "main_rng = random.PRNGKey(42)\n",
        "\n",
        "## Flax (NN in JAX)\n",
        "try:\n",
        "    import flax\n",
        "except ModuleNotFoundError: # Install flax if missing\n",
        "    !pip install --quiet flax\n",
        "    import flax\n",
        "from flax import linen as nn\n",
        "from flax.training import train_state, checkpoints\n",
        "\n",
        "## Optax (Optimizers in JAX)\n",
        "try:\n",
        "    import optax\n",
        "except ModuleNotFoundError: # Install optax if missing\n",
        "    !pip install --quiet optax\n",
        "    import optax\n",
        "\n",
        "## PyTorch Data Loading\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "from torchvision.datasets import CIFAR10\n",
        "\n",
        "# Tensorboard extension (for visualization purposes later)\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
        "DATASET_PATH = \"../../data\"\n",
        "# Path to the folder where the pretrained models are saved\n",
        "CHECKPOINT_PATH = \"../../saved_models/tutorial9_jax\"\n",
        "CHECKPOINT_PATH = os.path.abspath(CHECKPOINT_PATH)\n",
        "\n",
        "print(\"Device:\", jax.devices()[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(jax.devices())"
      ],
      "metadata": {
        "id": "KEIppKFdAHg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the SDF data"
      ],
      "metadata": {
        "id": "sb0Nq_GeZ8xU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "import scipy.ndimage\n",
        "from torch.utils.data import Subset\n",
        "\n",
        "\n",
        "class SignedDistanceTransform:\n",
        "    def __call__(self, img_tensor):\n",
        "        # Threshold.\n",
        "        img_tensor[img_tensor<0.5] = 0.\n",
        "        img_tensor[img_tensor>=0.5] = 1.\n",
        "\n",
        "        # Compute signed distances with distance transform\n",
        "        img_tensor = img_tensor.numpy()\n",
        "\n",
        "        neg_distances = scipy.ndimage.morphology.distance_transform_edt(img_tensor)\n",
        "        sd_img = img_tensor - 1.\n",
        "        sd_img = sd_img.astype(np.uint8)\n",
        "        signed_distances = scipy.ndimage.morphology.distance_transform_edt(sd_img) - neg_distances\n",
        "        signed_distances /= float(img_tensor.shape[1])\n",
        "        signed_distances = torch.Tensor(signed_distances)\n",
        "\n",
        "        return signed_distances, torch.Tensor(img_tensor)\n",
        "\n",
        "def get_mgrid(sidelen):\n",
        "    # Generate 2D pixel coordinates from an image of sidelen x sidelen\n",
        "    pixel_coords = np.stack(np.mgrid[:sidelen,:sidelen], axis=-1)[None,...].astype(np.float32)\n",
        "    pixel_coords /= sidelen\n",
        "    pixel_coords -= 0.5\n",
        "    pixel_coords = torch.Tensor(pixel_coords).view(-1, 2)\n",
        "    return pixel_coords\n",
        "\n",
        "class MNISTSDFDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, split, size=(256,256)):\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize(size),\n",
        "            transforms.ToTensor(),\n",
        "            SignedDistanceTransform(),\n",
        "        ])\n",
        "        self.img_dataset = torchvision.datasets.MNIST('./datasets/MNIST', train=True if split == 'train' else False,\n",
        "                                                download=True)\n",
        "        self.meshgrid = get_mgrid(size[0])\n",
        "        self.im_size = size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_dataset)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        img, digit_class = self.img_dataset[item]\n",
        "\n",
        "        signed_distance_img, binary_image = self.transform(img)\n",
        "\n",
        "        coord_values = self.meshgrid.reshape(-1, 2)\n",
        "        signed_distance_values = signed_distance_img\n",
        "        signed_distance_values = signed_distance_img.reshape((-1, 1))\n",
        "        image_values = binary_image.reshape((-1, 1))\n",
        "        side_len = int(np.sqrt(coord_values.shape[0]))\n",
        "        image_values_reshaped = binary_image.reshape(side_len, side_len, 1)\n",
        "        indices = torch.randperm(coord_values.shape[0])\n",
        "        support_indices = indices[:indices.shape[0]//2]\n",
        "        query_indices = indices[indices.shape[0]//2:]\n",
        "\n",
        "        meta_dict = {'images': (coord_values, image_values_reshaped), 'context': (coord_values[support_indices], signed_distance_values[support_indices]), 'query': (coord_values[query_indices], signed_distance_values[query_indices]), 'all': (coord_values, signed_distance_values, image_values_reshaped)}\n",
        "\n",
        "        return meta_dict"
      ],
      "metadata": {
        "id": "36UHyh68CEoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up dataloaders"
      ],
      "metadata": {
        "id": "sFcjbQHXaBLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MNISTSDFDataset('train', size=(28, 28))\n",
        "val_dataset = MNISTSDFDataset('val', size=(28, 28))\n",
        "test_dataset = MNISTSDFDataset('test', size=(28, 28))\n",
        "\n",
        "train_subset = Subset(train_dataset, list(range(1000)))\n",
        "val_subset = Subset(val_dataset, list(range(1000)))\n",
        "test_subset = Subset(test_dataset, list(range(1000)))\n",
        "\n",
        "train_dataloader = torch.utils.data.DataLoader(train_subset, batch_size=16)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_subset, batch_size=16)\n",
        "test_dataloader = torch.utils.data.DataLoader(test_subset, batch_size=16)"
      ],
      "metadata": {
        "id": "Ep6wqpKJCG9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_dataloader))\n",
        "coord_values, sdf_values, image_values = batch['all']\n",
        "image_values = (image_values).cpu().numpy()\n",
        "image_values.shape"
      ],
      "metadata": {
        "id": "7tEh8-WlD9P5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up the Encoder, Decoder and VAE classes"
      ],
      "metadata": {
        "id": "zuiYAclTab9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import flax.nnx as nnx\n",
        "\n",
        "class Encoder(nnx.Module):\n",
        "    def __init__(self, input_size: int, c_hid: int, latent_dim: int, *, rngs: nnx.Rngs):\n",
        "        self.c_hid = c_hid\n",
        "        self.input_size = input_size\n",
        "        self.latent_dim = latent_dim\n",
        "        self.rngs = rngs\n",
        "\n",
        "        # Define layers\n",
        "        self.conv1 = nnx.Conv(in_features=1, out_features=c_hid, kernel_size=(3, 3), strides=2, rngs=rngs, padding=\"SAME\")\n",
        "        self.conv2 = nnx.Conv(in_features=c_hid, out_features=c_hid, kernel_size=(3, 3), rngs=rngs, padding=\"SAME\")\n",
        "        self.conv3 = nnx.Conv(in_features=c_hid, out_features=2*c_hid, kernel_size=(3, 3), strides=2, rngs=rngs, padding=\"SAME\")\n",
        "        self.conv4 = nnx.Conv(in_features=2*c_hid, out_features=2*c_hid, kernel_size=(3, 3), rngs=rngs,  padding=\"SAME\")\n",
        "        self.conv5 = nnx.Conv(in_features=2*c_hid, out_features=2*c_hid, kernel_size=(3, 3), strides=2, rngs=rngs,  padding=\"SAME\")\n",
        "\n",
        "        self.fc_mean = nnx.Linear(rngs=rngs, in_features=1024, out_features=latent_dim)\n",
        "        self.fc_logvar = nnx.Linear(rngs=rngs, in_features=1024, out_features=latent_dim)\n",
        "\n",
        "    def __call__(self, x: jax.Array, *, deterministic: bool = False, key: jax.Array | None = None):\n",
        "        x = nnx.gelu(self.conv1(x))\n",
        "        x = nnx.gelu(self.conv2(x))\n",
        "        x = nnx.gelu(self.conv3(x))\n",
        "        x = nnx.gelu(self.conv4(x))\n",
        "        x = nnx.gelu(self.conv5(x))\n",
        "\n",
        "        x = x.reshape(x.shape[0], -1)  # flatten\n",
        "        mean = self.fc_mean(x)\n",
        "        logvar = jnp.clip(self.fc_logvar(x), -10, 10)\n",
        "        std = jnp.exp(0.5 * logvar)\n",
        "\n",
        "        if deterministic:\n",
        "            z = mean\n",
        "        else:\n",
        "            z = mean + std * jax.random.normal(self.rngs.noise(), mean.shape)\n",
        "\n",
        "        return z, mean, std\n"
      ],
      "metadata": {
        "id": "8gNPNgP0drYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nnx.Module):\n",
        "  def __init__(self, input_size: int, intermediate_size: int, output_size: int,\n",
        "               *, rngs: nnx.Rngs):\n",
        "    self.linear1 = nnx.Linear(input_size, intermediate_size, rngs=rngs)\n",
        "    self.linear2 = nnx.Linear(intermediate_size, intermediate_size, rngs=rngs)\n",
        "    self.linear2 = nnx.Linear(intermediate_size, intermediate_size, rngs=rngs)\n",
        "    self.linear2 = nnx.Linear(intermediate_size, output_size, rngs=rngs)\n",
        "\n",
        "  def __call__(self, z: jax.Array) -> jax.Array:\n",
        "    z = self.linear1(z)\n",
        "    z = jax.nn.relu(z)\n",
        "    logits = self.linear2(z)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "QDM0HVrUnHp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DeepSDF Decoder takes in a 2D coordinate + the latent vector learned from the encoder. This is different to the vanilla encoder above which just uses a latent. Currently, this is not working super well for reconstruction, the learned SDF values don't span the range -1 -> 1. A normal decoder is used to show the possibilities for sampling in latent space."
      ],
      "metadata": {
        "id": "aO6msGv6HaEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from typing import Sequence, Optional, Tuple\n",
        "# import jax\n",
        "# import jax.numpy as jnp\n",
        "# import flax.nnx as nnx\n",
        "\n",
        "# class Decoder(nnx.Module):\n",
        "#     latent_size: int\n",
        "#     dims: Sequence[int]\n",
        "#     dropout: Optional[Sequence[int]] = None\n",
        "#     dropout_prob: float = 0.0\n",
        "#     norm_layers: Tuple[int, ...] = ()\n",
        "#     latent_in: Tuple[int, ...] = ()\n",
        "#     xy_in_all: bool = False\n",
        "#     use_tanh: bool = False\n",
        "#     latent_dropout: bool = False\n",
        "\n",
        "#     def __init__(self,\n",
        "#                  latent_size: int,\n",
        "#                  dims: Sequence[int],\n",
        "#                  *,\n",
        "#                  rngs: nnx.Rngs,\n",
        "#                  dropout: Optional[Sequence[int]] = None,\n",
        "#                  dropout_prob: float = 0.0,\n",
        "#                  norm_layers: Tuple[int, ...] = (),\n",
        "#                  latent_in: Tuple[int, ...] = (),\n",
        "#                  xy_in_all: bool = False,\n",
        "#                  use_tanh: bool = False,\n",
        "#                  latent_dropout: bool = False):\n",
        "#         self.latent_size = latent_size\n",
        "#         self.dims = list(dims)\n",
        "#         self.dropout = dropout or []\n",
        "#         self.dropout_prob = dropout_prob\n",
        "#         self.norm_layers = norm_layers\n",
        "#         self.latent_in = latent_in\n",
        "#         self.xy_in_all = xy_in_all\n",
        "#         self.use_tanh = use_tanh\n",
        "#         self.latent_dropout = latent_dropout\n",
        "#         self.rngs = rngs\n",
        "\n",
        "#     def __call__(self, inputs: jax.Array, *, deterministic: bool = True):\n",
        "#         x = inputs\n",
        "#         xy = inputs[..., -2:]\n",
        "\n",
        "#         if self.latent_dropout and inputs.shape[-1] > 2:\n",
        "#             latent_vecs = inputs[..., :-2]\n",
        "#             latent_vecs = nnx.Dropout(rate=0.2)(latent_vecs, deterministic=deterministic)\n",
        "#             x = jnp.concatenate([latent_vecs, xy], axis=-1)\n",
        "\n",
        "#         dims = [self.latent_size + 2] + list(self.dims) + [1]\n",
        "#         num_layers = len(dims) - 1\n",
        "\n",
        "#         for layer in range(num_layers):\n",
        "#             if layer + 1 in self.latent_in:\n",
        "#                 out_dim = dims[layer + 1] - dims[0]\n",
        "#             else:\n",
        "#                 out_dim = dims[layer + 1]\n",
        "#                 if self.xy_in_all and layer != num_layers - 1:\n",
        "#                     out_dim -= 2\n",
        "\n",
        "#             if layer in self.latent_in:\n",
        "#                 x = jnp.concatenate([x, inputs], axis=-1)\n",
        "#             elif layer != 0 and self.xy_in_all:\n",
        "#                 x = jnp.concatenate([x, xy], axis=-1)\n",
        "\n",
        "#             # Linear\n",
        "#             x = nnx.Linear(x.shape[-1], out_dim, rngs=self.rngs)(x)\n",
        "\n",
        "#             # Hidden layers only\n",
        "#             if layer < num_layers - 1:\n",
        "#                 if layer in self.norm_layers:\n",
        "#                     x = nnx.LayerNorm(x.shape[-1], rngs=self.rngs)(x)\n",
        "#                 if layer < num_layers - 2:\n",
        "#                     x = nnx.relu(x)\n",
        "#                 if self.dropout and layer in self.dropout:\n",
        "#                     x = nnx.Dropout(rate=self.dropout_prob)(x, deterministic=deterministic)\n",
        "\n",
        "#         # x = jnp.tanh(x)\n",
        "#         return x  # shape (B, N, 1)\n"
      ],
      "metadata": {
        "id": "FdQItf75_OZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VAE(nnx.Module):\n",
        "  def __init__(\n",
        "    self,\n",
        "    image_shape: tuple[int, int],\n",
        "    hidden_size: int,\n",
        "    latent_size: int,\n",
        "    *,\n",
        "    rngs: nnx.Rngs\n",
        "  ):\n",
        "    self.image_shape = image_shape\n",
        "    self.latent_size = latent_size\n",
        "    input_size = image_shape[0] * image_shape[1]\n",
        "    self.encoder = Encoder(input_size, hidden_size, latent_size, rngs=rngs)\n",
        "    self.decoder = Decoder(latent_size, hidden_size, input_size, rngs=rngs)\n",
        "    # self.decoder = Decoder(\n",
        "    # latent_size=latent_size,\n",
        "    # dims=[512, 512, 256],\n",
        "    # rngs=rngs,\n",
        "    # dropout=[1],\n",
        "    # dropout_prob=0.1,\n",
        "    # norm_layers=(1,),\n",
        "    # xy_in_all=True,\n",
        "    # )\n",
        "  def __call__(self, x: jax.Array,  coords: jax.Array, *, deterministic: bool = False, key: jax.Array | None = None):\n",
        "\n",
        "    x = x.reshape(-1, 28, 28, 1)\n",
        "    z, mean, std = self.encoder(x, deterministic=deterministic, key=key)\n",
        "    z_hat = prepare_decoder_inputs(z, coords)\n",
        "    logits = self.decoder(z)  # or z_hat if deepsf\n",
        "\n",
        "\n",
        "    logits = jnp.reshape(logits, (-1, *self.image_shape))\n",
        "    return logits[...,None], mean, std"
      ],
      "metadata": {
        "id": "R-RiOCAHAp3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optax\n",
        "@nnx.jit\n",
        "def train_step(model: VAE, optimizer: nnx.Optimizer, x: jax.Array, coords: jax.Array):\n",
        "  loss, grads = nnx.value_and_grad(vae_loss)(model, x, coords)\n",
        "  optimizer = optimizer.update(grads)\n",
        "  return loss"
      ],
      "metadata": {
        "id": "bfhZ6atUBn2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_decoder_inputs(latent_vectors, coords):\n",
        "    B, N, _ = coords.shape\n",
        "    latent_expanded = jnp.expand_dims(latent_vectors, axis=1)  # (B,1,latent_dim)\n",
        "    latent_expanded = jnp.repeat(latent_expanded, N, axis=1)  # (B, N, latent_dim)\n",
        "    decoder_inputs = jnp.concatenate([latent_expanded, coords], axis=-1)  # (B, N, latent_dim+coord_dim)\n",
        "    return decoder_inputs"
      ],
      "metadata": {
        "id": "mfaRXN4HeHGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from jax import random, jit, vmap, lax, grad, value_and_grad\n",
        "@vmap\n",
        "def log_lik(x, x_reconstructed):\n",
        "  var = 1\n",
        "  x = x.flatten()\n",
        "  x_reconstructed = x_reconstructed.flatten()\n",
        "  diff = x-x_reconstructed\n",
        "  return -(1/var)*jnp.dot(diff, diff)\n",
        "\n",
        "@vmap\n",
        "def kl_divergence(mean, logstd):\n",
        "  return -0.5*jnp.sum(1 + 2*logstd - jnp.square(jnp.exp(logstd)) - jnp.square(mean))\n"
      ],
      "metadata": {
        "id": "chq-geAVBf3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training on the normalized SDF values"
      ],
      "metadata": {
        "id": "Dv7KciPmawjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vae_loss(model: VAE, x: jax.Array,coords: jax.Array ):\n",
        "  logits, mean, std = model(x, coords)\n",
        "  kl_loss = jnp.mean(0.5 * jnp.mean(\n",
        "      -jnp.log(std ** 2) - 1.0 + std ** 2 + mean ** 2, axis=-1))\n",
        "  # reconstruction_loss = jnp.mean(\n",
        "  #   optax.sigmoid_binary_cross_entropy(logits, x)\n",
        "  # )\n",
        "  # reconstruction_loss = jnp.mean((logits - x.reshape(-1, 28, 28, 1)) ** 2)  # use MSE\n",
        "  reconstruction_loss = - log_lik(x, logits).mean() + kl_divergence(mean, std).mean()\n",
        "  return reconstruction_loss +  kl_loss\n",
        "\n",
        "model = VAE(\n",
        "  image_shape=(28, 28),\n",
        "  hidden_size=32,\n",
        "  latent_size=256,\n",
        "  rngs=nnx.Rngs(0, noise=1),\n",
        ")\n",
        "dim_latent=256\n",
        "\n",
        "sdf_values= sdf_values.cpu().numpy()\n",
        "coord_values = coord_values.cpu().numpy()\n",
        "sdf_min = jnp.min(sdf_values, axis=1, keepdims=True)   # (B,1)\n",
        "sdf_max = jnp.max(sdf_values, axis=1, keepdims=True)   # (B,1)\n",
        "\n",
        "# scale to [-1,1]\n",
        "sdf_norm = 2 * (sdf_values - sdf_min) / (sdf_max - sdf_min + 1e-8) - 1\n",
        "\n",
        "optimizer = nnx.Optimizer(model, optax.adam(1e-3))\n",
        "for epoch in range(2001):\n",
        "  loss = train_step(model, optimizer, sdf_norm, coord_values)\n",
        "  if epoch % 500 == 0:\n",
        "    print(f'Epoch {epoch} loss: {loss}')"
      ],
      "metadata": {
        "id": "ygJH5czNBgAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate on test set"
      ],
      "metadata": {
        "id": "_39StIQpWzrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(test_dataloader))\n",
        "coord_values_test, sdf_values_test, image_values_test = batch['all']\n",
        "sdf_values_test = sdf_values_test.cpu().numpy()\n",
        "coord_values_test = coord_values_test.cpu().numpy()\n",
        "sdf_min_test = jnp.min(sdf_values_test, axis=1, keepdims=True)   # (B,1)\n",
        "sdf_max_test = jnp.max(sdf_values_test, axis=1, keepdims=True)   # (B,1)\n",
        "\n",
        "# scale to [-1,1]\n",
        "sdf_norm_test = 2 * (sdf_values_test - sdf_min_test) / (sdf_max_test - sdf_min_test + 1e-8) - 1\n",
        "logits, mean, std = model(sdf_norm_test, coord_values_test)\n",
        "images_pred = jax.nn.sigmoid(logits)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "XIuZuYdEFkP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Mean:\", mean.mean())\n",
        "print(\"Std\", std.std())\n",
        "print(\"SDF min and max:\", sdf_norm.min(), sdf_norm.max())\n",
        "print(\"Learned SDF min and max:\", logits.min(), logits.max())"
      ],
      "metadata": {
        "id": "TNDAHTBeK21t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checking reconstruction"
      ],
      "metadata": {
        "id": "gmo83Yuwa1TZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(2, 10, figsize=(10, 3.5),\n",
        "                       subplot_kw={'xticks':[], 'yticks':[]},\n",
        "                       gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
        "for i in range(10):\n",
        "\n",
        "  ax[0, i].imshow(sdf_norm_test.reshape(-1, 28, 28, 1)[i], cmap='viridis', interpolation='gaussian')\n",
        "  ax[1, i].imshow(images_pred[i], cmap='viridis', interpolation='gaussian')\n",
        "  ax[0, 0].set_ylabel(\"Input SDF\", rotation=0, size='large', labelpad=80, va='center')\n",
        "  ax[1, 0].set_ylabel(\"Reconstructed\", rotation=0, size='large', labelpad=80, va='center')"
      ],
      "metadata": {
        "id": "ijjRaazUFna0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating new images from sampling in latent space"
      ],
      "metadata": {
        "id": "2FP3r317a7Bu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# generate new images by sampling the latent space\n",
        "z = np.random.normal(scale=1, size=(36, model.latent_size))\n",
        "logits = model.decoder(z).reshape(-1, 28, 28)\n",
        "images_gen = nnx.sigmoid(logits)\n",
        "\n",
        "fig, ax = plt.subplots(6, 6, figsize=(10, 10),  # bigger figure\n",
        "                       subplot_kw={'xticks':[], 'yticks':[]},\n",
        "                       gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
        "for i in range(36):\n",
        "  ax.flat[i].imshow(images_gen[i], cmap='viridis', interpolation='gaussian')\n",
        "fig.suptitle(\"Generated Images from Latent Space\", fontsize=16)\n",
        "print()"
      ],
      "metadata": {
        "id": "5myVIDFUFuMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpolation in latent space"
      ],
      "metadata": {
        "id": "gnPQZ7Fxa_lf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z, _, _ = model.encoder(sdf_norm_test.reshape(-1, 28, 28, 1))\n",
        "# img = z[3]\n",
        "zrange = jnp.linspace(z[3], z[9], 10)\n",
        "\n",
        "logits = model.decoder(zrange).reshape(-1, 28, 28, 1)\n",
        "images_gen = nnx.sigmoid(logits)\n",
        "\n",
        "fig, ax = plt.subplots(1, 10, figsize=(12, 1),\n",
        "                       subplot_kw={'xticks':[], 'yticks':[]},\n",
        "                       gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
        "for i in range(10):\n",
        "  ax.flat[i].imshow(images_gen[i], cmap='viridis', interpolation='gaussian')\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "HAYwFQ07Fydq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Vanilla Autoencoder**"
      ],
      "metadata": {
        "id": "t64qvBqrD_ww"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdqaGi1Q00ZY"
      },
      "source": [
        "\n",
        "\n",
        "<center width=\"100%\"><img src=\"https://github.com/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial9/deconvolution.gif?raw=1\" width=\"250px\"></center>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GenerateCallback:\n",
        "\n",
        "    def __init__(self, input_imgs, coords, rng, every_n_epochs=1):\n",
        "        super().__init__()\n",
        "        self.input_imgs = input_imgs  # Images to reconstruct during training\n",
        "        self.coords = coords\n",
        "        self.every_n_epochs = every_n_epochs  # Only save those images every N epochs (otherwise tensorboard gets quite large)\n",
        "        self.rng_noise, self.rng_dropout = jax.random.split(rng, 2)\n",
        "\n",
        "    def log_generations(self, model, state, logger, epoch):\n",
        "        if epoch % self.every_n_epochs == 0:\n",
        "            reconst_sdf, mu, std = model.apply({'params': state.params}, self.input_imgs.cpu().numpy(), self.coords.cpu().numpy(), rngs={'noise': self.rng_noise, 'dropout': self.rng_dropout}, deterministic=True)\n",
        "            reconst_imgs = np.array(reconst_imgs)\n",
        "            # # Plot and add to tensorboard\n",
        "            # imgs = np.stack([self.input_imgs, reconst_imgs], axis=1).reshape(-1, *self.input_imgs.shape[1:])\n",
        "            # imgs = jax_to_torch(imgs)\n",
        "            # grid = torchvision.utils.make_grid(imgs, nrow=2, normalize=True, value_range=(-1,1))\n",
        "            # logger.add_image(\"Reconstructions\", grid, global_step=epoch)"
      ],
      "metadata": {
        "id": "rOej5jAicdco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VanillaEncoder(nn.Module):\n",
        "    c_hid : int\n",
        "    latent_dim : int\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "        x = nn.Conv(features=self.c_hid, kernel_size=(3, 3), strides=2)(x)  # 32x32 => 16x16\n",
        "        x = nn.gelu(x)\n",
        "        x = nn.Conv(features=self.c_hid, kernel_size=(3, 3))(x)\n",
        "        x = nn.gelu(x)\n",
        "        x = nn.Conv(features=2*self.c_hid, kernel_size=(3, 3), strides=2)(x)  # 16x16 => 8x8\n",
        "        x = nn.gelu(x)\n",
        "        x = nn.Conv(features=2*self.c_hid, kernel_size=(3, 3))(x)\n",
        "        x = nn.gelu(x)\n",
        "        x = nn.Conv(features=2*self.c_hid, kernel_size=(3, 3), strides=2)(x)  # 8x8 => 4x4\n",
        "        x = nn.gelu(x)\n",
        "        x = x.reshape(x.shape[0], -1)  # Image grid to single feature vector\n",
        "        x = nn.Dense(features=self.latent_dim)(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "ekF3jG6fzkEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Sequence, Optional, Tuple\n",
        "# LIPSCHITZ REGULARIZATION ADDED TO DECODER\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    latent_size: int\n",
        "    dims: Sequence[int]\n",
        "    dropout: Optional[Sequence[int]] = None\n",
        "    dropout_prob: float = 0.0\n",
        "    norm_layers: Tuple[int, ...] = ()\n",
        "    latent_in: Tuple[int, ...] = ()\n",
        "    xy_in_all: bool = False\n",
        "    use_tanh: bool = False\n",
        "    latent_dropout: bool = False\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, inputs, *, deterministic: bool):\n",
        "        # inputs: (B, N, latent_size + 2)\n",
        "        x = inputs\n",
        "        xy = inputs[..., -2:]  # (B, N, 2)\n",
        "\n",
        "        if inputs.shape[-1] > 2 and self.latent_dropout:\n",
        "            latent_vecs = inputs[..., :-2]  # (B, N, latent_size)\n",
        "            latent_vecs = nn.Dropout(rate=0.2)(latent_vecs, deterministic=deterministic)\n",
        "            x = jnp.concatenate([latent_vecs, xy], axis=-1)\n",
        "\n",
        "        num_layers = len(self.dims) + 2\n",
        "        dims = [self.latent_size + 2] + list(self.dims) + [1]\n",
        "\n",
        "        for layer in range(num_layers - 1):\n",
        "            if layer + 1 in self.latent_in:\n",
        "                out_dim = dims[layer + 1] - dims[0]\n",
        "            else:\n",
        "                out_dim = dims[layer + 1]\n",
        "                if self.xy_in_all and layer != num_layers - 2:\n",
        "                    out_dim -= 2\n",
        "\n",
        "            if layer in self.latent_in:\n",
        "                x = jnp.concatenate([x, inputs], axis=-1)\n",
        "            elif layer != 0 and self.xy_in_all:\n",
        "                x = jnp.concatenate([x, xy], axis=-1)\n",
        "\n",
        "            # nn.Dense applies last axis -> out_dim\n",
        "            x = nn.Dense(out_dim, name=f\"lin{layer}\")(x)\n",
        "\n",
        "            if layer == num_layers - 2 and self.use_tanh:\n",
        "                x = jnp.tanh(x)\n",
        "\n",
        "            if layer < num_layers - 2:\n",
        "                if self.norm_layers and layer in self.norm_layers:\n",
        "                    # LayerNorm on last axis, supports (B, N, features)\n",
        "                    x = nn.LayerNorm(name=f\"bn{layer}\")(x)\n",
        "                x = nn.relu(x)\n",
        "                if self.dropout and layer in self.dropout:\n",
        "                    x = nn.Dropout(rate=self.dropout_prob)(x, deterministic=deterministic)\n",
        "\n",
        "        # if self.use_tanh:\n",
        "        #     x = jnp.tanh(x)\n",
        "        return x  # shape (B, N, 1)"
      ],
      "metadata": {
        "id": "kvGJbVmgAn67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_decoder_inputs(latent_vectors, coords):\n",
        "    B, N, _ = coords.shape\n",
        "    latent_expanded = jnp.expand_dims(latent_vectors, axis=1)  # (B,1,latent_dim)\n",
        "    latent_expanded = jnp.repeat(latent_expanded, N, axis=1)  # (B, N, latent_dim)\n",
        "    decoder_inputs = jnp.concatenate([latent_expanded, coords], axis=-1)  # (B, N, latent_dim+coord_dim)\n",
        "    return decoder_inputs"
      ],
      "metadata": {
        "id": "EzyR8-HbE4Wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VanillaAutoencoder(nn.Module):\n",
        "    c_hid: int\n",
        "    latent_dim : int\n",
        "\n",
        "    def setup(self):\n",
        "        # Alternative to @nn.compact -> explicitly define modules\n",
        "        # Better for later when we want to access the encoder and decoder explicitly\n",
        "        self.encoder = VanillaEncoder(c_hid=self.c_hid, latent_dim=self.latent_dim)\n",
        "        self.decoder = Decoder(\n",
        "        latent_size=self.latent_dim,\n",
        "        dims=[259, 1024, 1024, 1024, 512, 256, 128],  # hidden dims\n",
        "        dropout=[1, 2],\n",
        "        dropout_prob=0.1,\n",
        "        norm_layers=(0, 1),\n",
        "        latent_in=(1,),\n",
        "        xy_in_all=True,\n",
        "        use_tanh=True,\n",
        "        latent_dropout=True,\n",
        "    )\n",
        "\n",
        "    def __call__(self, x, coord, *, deterministic=False):\n",
        "        z = self.encoder(x)\n",
        "        z_hat = prepare_decoder_inputs(z, coord)\n",
        "        x_hat = self.decoder(z_hat, deterministic=deterministic)\n",
        "        return x_hat\n",
        "\n",
        "    def encode(self, imgs):\n",
        "      return self.encoder(imgs)\n",
        "\n",
        "    def decode(self, z, coords, deterministic=False):\n",
        "      z_hat = prepare_decoder_inputs(z, coords)\n",
        "      x_hat = self.decoder(z_hat, deterministic=deterministic)\n",
        "      return x_hat"
      ],
      "metadata": {
        "id": "IRxEBX2d-yQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorboard as tb\n",
        "\n",
        "def to_jax(obj):\n",
        "    \"\"\"Recursively convert torch tensors in nested dicts/tuples/lists to jnp arrays.\"\"\"\n",
        "    if isinstance(obj, torch.Tensor):\n",
        "        return jnp.array(obj.cpu().numpy())\n",
        "    elif isinstance(obj, dict):\n",
        "        return {k: to_jax(v) for k, v in obj.items()}\n",
        "    elif isinstance(obj, (list, tuple)):\n",
        "        return type(obj)(to_jax(v) for v in obj)\n",
        "    else:\n",
        "        return obj\n",
        "\n",
        "def jax_to_torch(imgs):\n",
        "    imgs = jax.device_get(imgs)\n",
        "    imgs = torch.from_numpy(imgs.astype(np.float32))\n",
        "    imgs = imgs.permute(0, 3, 1, 2)\n",
        "    return imgs"
      ],
      "metadata": {
        "id": "ljE1RoS9FIG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training setup class"
      ],
      "metadata": {
        "id": "P9qVonLCbSqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainerModule:\n",
        "\n",
        "    def __init__(self, c_hid, latent_dim, lr=1e-3, seed=42):\n",
        "        super().__init__()\n",
        "        self.c_hid = c_hid\n",
        "        self.latent_dim = latent_dim\n",
        "        self.lr = lr\n",
        "        self.seed = seed\n",
        "        # Create empty model. Note: no parameters yet\n",
        "        # self.model = Autoencoder(c_hid=self.c_hid, latent_dim=self.latent_dim)\n",
        "        self.model = VanillaAutoencoder(c_hid=self.c_hid, latent_dim=self.latent_dim)\n",
        "        # self.model = VAE(\n",
        "        #   image_shape=(32, 32),\n",
        "        #   hidden_size=c_hid,\n",
        "        #   latent_size=latent_dim,\n",
        "        #   rngs=nnx.Rngs(0, noise=1),\n",
        "        # )\n",
        "        # Setup\n",
        "        imgs = next(iter(train_dataloader))\n",
        "        self.coord_values, _, self.image_values = imgs['all']\n",
        "        self.create_functions()\n",
        "        self.rng = jax.random.PRNGKey(seed)\n",
        "        # Prepare logging\n",
        "        self.exmp_imgs = next(iter(val_dataloader))['all'][1][:16]\n",
        "        self.coords_logging = next(iter(val_dataloader))['all'][0][:16]\n",
        "        self.log_dir = os.path.join(CHECKPOINT_PATH, f'cifar10_{self.latent_dim}')\n",
        "        self.generate_callback = GenerateCallback(self.exmp_imgs, self.coords_logging, self.rng, every_n_epochs=51)\n",
        "        self.logger = SummaryWriter(log_dir=self.log_dir)\n",
        "        # Initialize model\n",
        "        self.init_model()\n",
        "\n",
        "    def create_functions(self):\n",
        "        # Training function\n",
        "        def train_step(state, batch, rng):\n",
        "            rng, noise_rng, dropout_rng = jax.random.split(rng, 3)\n",
        "            loss_fn = lambda params: self.mse_recon_loss(self.model, params, batch, noise_rng, dropout_rng, deterministic=False)\n",
        "            # loss_fn = lambda params: self.vae_loss(self.model, params, batch, noise_rng, dropout_rng, deterministic=False)\n",
        "            loss, grads = jax.value_and_grad(loss_fn)(state.params)  # Get loss and gradients for loss\n",
        "            state = state.apply_gradients(grads=grads)  # Optimizer update step\n",
        "            return state, loss, rng\n",
        "        self.train_step = jax.jit(train_step)\n",
        "        # Eval function\n",
        "        def eval_step(state, batch):\n",
        "            # return self.vae_loss(self.model, state.params, batch, deterministic=True)\n",
        "            return self.mse_recon_loss(self.model, state.params, batch, deterministic=True)\n",
        "        self.eval_step = jax.jit(eval_step)\n",
        "\n",
        "    def init_model(self):\n",
        "        # Initialize model\n",
        "\n",
        "        self.rng, rng_init, rng_noise, rng_dropout = jax.random.split(self.rng, 4)\n",
        "        variables = self.model.init({'params': rng_init, 'noise': rng_noise, 'dropout': rng_dropout},\n",
        "                             self.image_values, self.coord_values.cpu().numpy())\n",
        "        params = variables['params']\n",
        "        # Initialize learning rate schedule and optimizer\n",
        "        lr_schedule = optax.warmup_cosine_decay_schedule(\n",
        "            init_value=0.0,\n",
        "            peak_value=1e-3,\n",
        "            warmup_steps=100,\n",
        "            decay_steps=500*len(train_dataloader),\n",
        "            end_value=1e-5\n",
        "        )\n",
        "        optimizer = optax.chain(\n",
        "            optax.clip(1.0),  # Clip gradients at 1\n",
        "            optax.adam(lr_schedule)\n",
        "        )\n",
        "        # Initialize training state\n",
        "        self.state = train_state.TrainState.create(apply_fn=self.model.apply, params=params, tx=optimizer)\n",
        "\n",
        "    def train_model(self, num_epochs=1):\n",
        "        # Train model for defined number of epochs\n",
        "        best_eval = 1e6\n",
        "        for epoch_idx in tqdm(range(1, num_epochs+1)):\n",
        "            self.train_epoch(epoch=epoch_idx)\n",
        "            if epoch_idx % 50 == 0:\n",
        "                eval_loss = self.eval_model(val_dataloader)\n",
        "                self.logger.add_scalar('val/loss', eval_loss, global_step=epoch_idx)\n",
        "                print(f\"Epoch: {epoch_idx}, Val loss: {eval_loss}\")\n",
        "                if eval_loss < best_eval:\n",
        "                    best_eval = eval_loss\n",
        "                    self.save_model(step=epoch_idx)\n",
        "                self.generate_callback.log_generations(self.model, self.state, logger=self.logger, epoch=epoch_idx)\n",
        "                self.logger.flush()\n",
        "\n",
        "    def mse_recon_loss(self, model, params, batch, noise_rng=None, rng_dropout=None, deterministic=True):\n",
        "        coord_values, sdf_values, image_values = batch['all']\n",
        "        sdf_values = to_jax(sdf_values)\n",
        "        rngs = {}\n",
        "        if not deterministic:\n",
        "          rngs = {'noise': noise_rng, 'dropout': rng_dropout}\n",
        "        pred_sd = model.apply({'params': params}, image_values, coord_values, rngs=rngs, deterministic=deterministic)\n",
        "        return jnp.mean((pred_sd - sdf_values) ** 2)\n",
        "\n",
        "    def train_epoch(self, epoch):\n",
        "        # Train model for one epoch, and log avg loss\n",
        "        losses = []\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch = to_jax(batch)\n",
        "            self.state, loss, self.rng = self.train_step(self.state, batch, self.rng)\n",
        "            losses.append(loss)\n",
        "            # print('step', step)\n",
        "        losses_np = np.stack(jax.device_get(losses))\n",
        "        avg_loss = losses_np.mean()\n",
        "        self.logger.add_scalar('train/loss', avg_loss, global_step=epoch)\n",
        "        print(f\"Epoch: {epoch}, Train loss: {avg_loss}\")\n",
        "\n",
        "\n",
        "    def eval_model(self, data_loader):\n",
        "        # Test model on all images of a data loader and return avg loss\n",
        "        losses = []\n",
        "        batch_sizes = []\n",
        "        for batch in data_loader:\n",
        "            batch = to_jax(batch)\n",
        "            loss = self.eval_step(self.state, batch)\n",
        "            losses.append(loss)\n",
        "            batch_sizes.append(batch['all'][0].shape[0])\n",
        "        losses_np = np.stack(jax.device_get(losses))\n",
        "        batch_sizes_np = np.stack(batch_sizes)\n",
        "        avg_loss = (losses_np * batch_sizes_np).sum() / batch_sizes_np.sum()\n",
        "        return avg_loss\n",
        "\n",
        "    def generate(self, coords, params, key):\n",
        "      self.rng, key = jax.random.split(self.rng)\n",
        "      z = 0.1 * jax.random.normal(key, shape=(1, self.latent_dim))\n",
        "      return self.model.apply({'params': params}, z, coords, method=self.model.decode, deterministic=True)\n",
        "\n",
        "    def interpolate(self, params, image_1, image_2, coords, alpha, deterministic=True):\n",
        "        z1 = self.model.apply({'params': params}, image_1, method=self.model.encode)\n",
        "        z2 = self.model.apply({'params': params}, image_2, method=self.model.encode)\n",
        "\n",
        "        # z1, _, _ = self.model.apply({'params': params}, image_1, method=self.model.encode, deterministic=deterministic)\n",
        "        # z2, _, _ = self.model.apply({'params': params}, image_2, method=self.model.encode, deterministic=deterministic)\n",
        "        z_interp = z1*(1-alpha) + alpha*z2\n",
        "        return self.model.apply({'params': params}, z_interp, coords, method=self.model.decode, deterministic=True)\n",
        "\n",
        "    def save_model(self, step=0):\n",
        "        # Save current model at certain training iteration\n",
        "        checkpoints.save_checkpoint(ckpt_dir=self.log_dir, target=self.state.params, prefix=f'cifar10_{self.latent_dim}_', step=step, overwrite=True)\n",
        "\n",
        "    def load_model(self, pretrained=False):\n",
        "        # Load model. We use different checkpoint for pretrained models\n",
        "        if not pretrained:\n",
        "            params = checkpoints.restore_checkpoint(ckpt_dir=self.log_dir, target=self.state.params, prefix=f'cifar10_{self.latent_dim}_')\n",
        "        else:\n",
        "            params = checkpoints.restore_checkpoint(ckpt_dir=os.path.join(CHECKPOINT_PATH, f'cifar10_{self.latent_dim}.ckpt'), target=self.state.params)\n",
        "        self.state = train_state.TrainState.create(apply_fn=self.model.apply, params=params, tx=self.state.tx)\n",
        "\n",
        "    def checkpoint_exists(self):\n",
        "        # Check whether a pretrained model exist for this autoencoder\n",
        "        return os.path.isfile(os.path.join(CHECKPOINT_PATH, f'cifar10_{self.latent_dim}.ckpt'))"
      ],
      "metadata": {
        "id": "6gqoRoCJFEU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vanilla Autoencoder Results"
      ],
      "metadata": {
        "id": "k0OPBk3p9zMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_results(trainer, coords, sdfs, imgs, num_samples=4):\n",
        "    \"\"\"\n",
        "    Visualize original image, original SDF, and reconstructed SDF for a few samples.\n",
        "\n",
        "    Args:\n",
        "        trainer: TrainerModule with model_bd bound to trained params.\n",
        "        batch: A batch from the dataset in JAX/Torch/Numpy form.\n",
        "        num_samples: Number of examples to visualize.\n",
        "    \"\"\"\n",
        "    coords = coords.cpu().numpy()\n",
        "    sdfs = sdfs.cpu().numpy()\n",
        "    imgs = imgs.cpu().numpy()\n",
        "\n",
        "\n",
        "    # Take only the first num_samples\n",
        "    coords = coords[:num_samples]\n",
        "    sdfs = sdfs[:num_samples]\n",
        "    imgs = imgs[:num_samples]\n",
        "\n",
        "\n",
        "    # Predict reconstructed SDF\n",
        "    reconst_sdf = trainer.model.apply(\n",
        "    {'params': trainer.state.params},\n",
        "    imgs,\n",
        "    coords,\n",
        "    rngs={'dropout': jax.random.PRNGKey(0)}  # fixed RNG for deterministic eval\n",
        "    )\n",
        "    # reconst_sdf = trainer.model_bd(imgs_reshaped, coords)\n",
        "    reconst_sdf = np.array(reconst_sdf)\n",
        "    side_len = int(np.sqrt(coords.shape[1]))\n",
        "    # Plot each example\n",
        "    fig, axes = plt.subplots(num_samples, 3, figsize=(9, 3*num_samples))\n",
        "    if num_samples == 1:\n",
        "        axes = axes[None, :]  # keep indexing consistent\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        # Original image\n",
        "        axes[i, 0].imshow(imgs[i, ..., 0], cmap='gray')\n",
        "        axes[i, 0].set_title(\"Original Image\")\n",
        "        axes[i, 0].axis('off')\n",
        "\n",
        "        # Original SDF\n",
        "        axes[i, 1].imshow(sdfs[i].reshape(side_len, side_len), cmap='viridis')\n",
        "        axes[i, 1].set_title(\"Original SDF\")\n",
        "        axes[i, 1].axis('off')\n",
        "\n",
        "        # Reconstructed SDF\n",
        "        axes[i, 2].imshow(reconst_sdf[i].reshape(side_len, side_len), cmap='viridis')\n",
        "        axes[i, 2].set_title(\"Reconstructed SDF\")\n",
        "        axes[i, 2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def interpolate(trainer, img1, img2):\n",
        "  coords_one = trainer_ld.coord_values[0:1]  # shape (1, N, 2)\n",
        "\n",
        "  alphas = np.linspace(0,1,6)\n",
        "  fig, axes = plt.subplots(1, len(alphas), figsize=(3*len(alphas), 3))\n",
        "\n",
        "  for i, a in enumerate(alphas):\n",
        "    pred_sdf = trainer_ld.interpolate(\n",
        "        params=trainer_ld.state.params,\n",
        "        image_1=img1, image_2=img2,\n",
        "        coords=coords_one.cpu().numpy(),\n",
        "        alpha=a,\n",
        "    )\n",
        "    pred_sdf = np.array(pred_sdf)\n",
        "    side_len = int(np.sqrt(coords_one.shape[1]))\n",
        "    sdf_img = pred_sdf.reshape(side_len, side_len)\n",
        "    ax = axes[i]\n",
        "    # norm = colors.TwoSlopeNorm(vmin=-1, vcenter=0, vmax=1)\n",
        "    im = ax.imshow(sdf_img, cmap=\"seismic\", origin=\"upper\")\n",
        "    ax.set_title(f\"α={a:.1f}\")\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "\n",
        "  plt.colorbar(im, ax=axes.ravel().tolist(), shrink=0.6)\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "def generate(trainer):\n",
        "  coords_one = trainer_ld.coord_values[0:1]  # shape (1, N, 2)\n",
        "\n",
        "  # Generate prediction from random latent\n",
        "  pred_sdf = trainer_ld.generate(\n",
        "      coords=coords_one.cpu().numpy(),\n",
        "      key=jax.random.PRNGKey(0),\n",
        "      params=trainer_ld.state.params\n",
        "  )\n",
        "\n",
        "  # Convert to NumPy\n",
        "  pred_sdf = np.array(pred_sdf)\n",
        "\n",
        "  # Reshape to square image\n",
        "  side_len = int(np.sqrt(coords_one.shape[1]))\n",
        "  pred_img = pred_sdf.reshape(side_len, side_len)\n",
        "\n",
        "  # Plot SDF field\n",
        "  plt.figure(figsize=(4, 4))\n",
        "  plt.imshow(pred_img, cmap='coolwarm', origin='lower')\n",
        "  plt.colorbar(label=\"SDF value\")\n",
        "  plt.title(\"Generated SDF\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "QVuHnIaV9sa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_cifar(latent_dim, n_epochs, c_hid):\n",
        "    # Create a trainer module with specified hyperparameters\n",
        "    trainer = TrainerModule(c_hid=c_hid, latent_dim=latent_dim)\n",
        "    if not trainer.checkpoint_exists():  # Skip training if pretrained model exists\n",
        "      trainer.train_model(num_epochs=n_epochs)\n",
        "      trainer.load_model()\n",
        "    else:\n",
        "        trainer.load_model(pretrained=True)\n",
        "    test_loss = trainer.eval_model(val_dataloader)\n",
        "    # Bind parameters to model for easier inference\n",
        "    trainer.model_bd = trainer.model.bind({'params': trainer.state.params})\n",
        "    return trainer, test_loss"
      ],
      "metadata": {
        "id": "G7RQzQHhcYrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent = [64, 128, 256]\n",
        "n_epochs = 5\n",
        "c_hid = 32\n",
        "model_dict = {}\n",
        "for latent_dim in latent:\n",
        "    trainer_ld, test_loss_ld = train_cifar(latent_dim, n_epochs, c_hid)\n",
        "    model_dict[latent_dim] = {\"trainer\": trainer_ld, \"result\": test_loss_ld}\n",
        "    print('Test Loss', test_loss_ld)"
      ],
      "metadata": {
        "id": "pM3YtZrpcQ2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate on test set"
      ],
      "metadata": {
        "id": "BEIxziC4V9G-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(test_dataloader))\n",
        "\n",
        "# Visualize results for first 4 samples\n",
        "coord_values, sdf_values, image_values = batch['all']\n",
        "visualize_results(model_dict[latent_dim][\"trainer\"], coord_values, sdf_values, image_values, num_samples=4)"
      ],
      "metadata": {
        "id": "ZvBUVW4I9uFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generation and interpolation in latent space"
      ],
      "metadata": {
        "id": "kk79Ia2dbcca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = trainer_ld.model.apply({'params': trainer_ld.state.params}, image_values.cpu().numpy(), method=trainer_ld.model.encode)\n",
        "generate(trainer_ld)\n",
        "print(pred.mean(), pred.std())"
      ],
      "metadata": {
        "id": "5_xz6sUL-frz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_1 = image_values[0][None,...]\n",
        "img_2 = image_values[2][None,...]\n",
        "interpolate(trainer_ld, img_1, img_2)"
      ],
      "metadata": {
        "id": "HA3xJlTSbnGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3FPR94j00Za"
      },
      "source": [
        "We can train across multiple latent dimensions to see how it affects reconstruction accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmS8MG8T00Za"
      },
      "outputs": [],
      "source": [
        "latent_dims = sorted([k for k in model_dict])\n",
        "val_scores = [model_dict[k][\"result\"] for k in latent_dims]\n",
        "\n",
        "fig = plt.figure(figsize=(6,4))\n",
        "plt.plot(latent_dims, val_scores, '--', color=\"#000\", marker=\"*\", markeredgecolor=\"#000\", markerfacecolor=\"y\", markersize=16)\n",
        "plt.xscale(\"log\")\n",
        "plt.xticks(latent_dims, labels=latent_dims)\n",
        "plt.title(\"Reconstruction error over latent dimensionality\", fontsize=14)\n",
        "plt.xlabel(\"Latent dimensionality\")\n",
        "plt.ylabel(\"Reconstruction error\")\n",
        "plt.minorticks_off()\n",
        "plt.ylim(0,0.01)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_scores"
      ],
      "metadata": {
        "id": "rhHIGHMCYt0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dnIDWdohb2R0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}